## Computational Issue with the Current Implementation

One of the major computational challenge we saw in the algorithm presented in the [project report](https://kory33.github.io/guarded-queries/report.pdf) was that we *always* have to visit the whole space of the "subquery entailment instance"s, whose size is doubly-exponential in the maximum arity $K$ and exponential in some other factors. To be more precise, the upper bound for the number of such instances we gave in the paper (Remark 4.18) was $$2^{|\text{sig}|(K + |\mathrm{Consts}|(\Sigma))^K + \mathrm{Vars}(Q)} \times (K + |\mathrm{Consts}|(\Sigma))^{\mathrm{Vars}(Q)},$$where $Q$ is the conjunctive query, $\Sigma$ is the GTGD rule set, $\mathrm{sig}$ is the set of predicate symbols and $K$ is the maximum arity of symbols in $\mathrm{sig}$.

We identified that we may be able to exponentially cut down the search space by considering subsumptions: for instance, suppose that we concluded that a local instance $\mathcal{I}_0$ is sufficient to entail a subquery $Q$, then for any local renaming $\sigma$ (that does not remap local names that are already bound to variables in the subquery) and any local instance $\tilde{\mathcal{I}}$ with $\sigma(\mathcal{I}_0) \subseteq \tilde{\mathcal{I}}$, $\tilde{\mathcal{I}}$ is sufficient to entail $Q$. Such reasonings allow us to, for instance, skip all subquery entailment tests for local instances such as $\{ P(1, 1) \}, \{ P(1, 3) \}, \{ P(2, 1) \}, \{ P(1, 2), S(1) \}, ...$ once we know that a minimal instance $\{P(1, 2)\}$ is sufficient to entail the subquery in question.

This optimization sounds plausible, but the difficulty lies in "finding the next interesting subquery entailment instance" given the set of all "minimal" query-entailing instances. One naive approach is simply to iterate through every possible subquery entailment instances and filter out instances that are subsumed by minimal instances found previously: however, this still requires us to go through doubly exponentially many local instances, and we estimated that such implementation cannot drastically improve the overall runtime (in fact it may even be slower due to running subsumption tests every time we visit a new subquery entailment instance). There may actually be a good algorithm for efficiently enumerating "next interesting" point in the space of instances partially ordered by subsumption relation, but we could not come up with one.

## Revisiting the Intuition of Tree Automaton for BCQ Evaluation

Stepping back, our idea to the algorithm was the following (only some of which appeared in the [project report](https://kory33.github.io/guarded-queries/report.pdf)):
 - We have *shortcutting chase trees* as tree-like universal models which can be semicomputed (i.e. computed upto a certain depth) without backtracking. $\mathrm{GSat}$ is an important underlying step here as it essentially *precomputes by resolution* all backtracking steps required to perform chase proofs.
 - As the shortcutting chase tree is tree-like, we can construct tree automatons that recognize (the implicit-equality-coded tree-code of) finite subgraphs of the shortcutting chase tree. In fact, we can decide if a local instance (with some partial binding from query variables to active local names) entails a (*connected*) subquery by checking whether the language $L(\mathcal{A}_\mathrm{query} \times \mathcal{A}_\mathrm{chase})$ is nonempty (since any $T \in L(\mathcal{A}_\mathrm{query} \times \mathcal{A}_\mathrm{chase})$ corresponds to a valid chase proof from the root instance to the query), where
	 - $\mathcal{A}_\mathrm{query}$ is the *query automaton*, which is a (top-down-)nondeterministic tree automaton where a state is a triple of
		 - a yet-to-be-satisfied part of the subquery,
		 - the current local instance (i.e. the local instance that the automaton last saw as it is descending the tree), and
		 - the local name bindings from free-variables of the subquery to local names active in the current local instance.
	   The automaton
		 - requires (by falling into the sink state if the condition is not met) that no local name bound by a variable is "dropped" (i.e. *stop appearing* in the local instance) during the chase step, and
		 - nondeterministically *commits* a nonempty subset of existentially quantified variables (that are not yet bound to local names) to the active local names at the current node, subject to conditions that:
			 - all *newly fully-committed atoms* must appear in the current local instance,
				 - where an atom $A_i$ is *newly fully-committed* in the subquery $Q = \exists \vec{z}. \bigwedge_{j \in J} A_i$ (where each $A_j$ contains at least one bound variable) upon a commit $\sigma: (\mathrm{Vars}(Q) \setminus \mathrm{FV}(Q)) \rightharpoonup \mathrm{ActiveLocalNames}(\mathcal{I})$ if $\mathrm{Vars}(A_i) \setminus \mathrm{FV}(Q) \subseteq \mathrm{dom}(\sigma)$.
			 - after the commit has been made, the query in the state is split into queries induced by connected components of yet-to-be-bound quantified variables, and each component is nondeterministically allocated a subtree of the input tree to further check subquery entailment.
	 - $\mathcal{A}_\mathrm{chase}$ is the *chase automaton*, which is a (bottom-up-)deterministic tree automaton that checks whether the input tree is a fragment of the shortcutting chase tree of the root instance. More precisely, $\mathcal{A}_\mathrm{chase}$ has the current instance (as in $\mathcal{A}_\mathrm{query}$) as a state, and 
	 - $\mathcal{A}_\mathrm{query} \times \mathcal{A}_\mathrm{chase}$ is the product automaton.

The important observation is that the state space of $\mathcal{A}_\mathrm{query}$ is partially ordered (by reachability) and is well-founded: a subquery in the state of $\mathcal{A}_\mathrm{query}$ either remains the same (when $\mathcal{A}_\mathrm{query}$ thinks that no commit should happen), or is split into multiple smaller subqueries whenever $\mathcal{A}_\mathrm{query}$ decides to commit a nonempty subset of bound variables in the original subquery.

This partial order carries over to the product automaton $\mathcal{A}_\mathrm{query} \times \mathcal{A}_\mathrm{chase}$ as a preorder (again, by reachability) that is "fintely stratified" by the partial and well-founded ordering of states from $\mathcal{A}_\mathrm{query}$.

Our first implementation was based on the idea that we can keep running the foward-reachability test from the "bottom layer" of $\mathcal{A}_\mathrm{query}$, thereby first enumerating all "good" instances with respect to smaller subqueries, and then inductively going up the layer (which corresponds to increasing the subquery size) to find all good instances with respect to all subqueries. When a subquery is fixed, we only need to decide the set of instances that can be chased down to a "splitting point", so the problem is more like deciding the set of letters within the alphabet that leads to an accepting state of a deterministic word automaton (because $\mathcal{A}_\mathrm{chase}$ is a deterministic automaton, and while $\mathcal{A}_\mathrm{query}$ *stays* at a particular state, the product automaton is constrained to only accept a linear tree, therefore under this setting, $\mathcal{A}_\mathrm{chase}$ *really does behave like* a deterministic word automaton).

## How about Using Backward Reachability Tests, then?

(TODO; write on why we initially rejected the idea, why the forward reachability approach workded to a certain extend and finally write how we could possibly exploit the stratified structure of $\mathcal{A}_\mathrm{query}$ to perform the backward reachability test, similar to how we exploited the structure in the forward reachability test)